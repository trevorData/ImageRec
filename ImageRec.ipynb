{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Documents/Projects/ImageRec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_save(query_term, offset):\n",
    "    '''\n",
    "    saves and processes images for specified query, creates folder in directory if there isnt one\n",
    "    '''\n",
    "    \n",
    "    API_KEY = os.getenv('bing_search_api_key')\n",
    "    URL = \"https://api.cognitive.microsoft.com/bing/v7.0/images/search\"\n",
    "    USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)' + \\\n",
    "                 'Chrome/80.0.3987.87 Safari/537.36'\n",
    "    \n",
    "    # set path with query term as file name\n",
    "    path = os.getcwd().replace('\\\\', '/') + '/' + str(query_term) + '/'\n",
    "    \n",
    "    if not os.path.exists(query_term):\n",
    "        # if the directory does not exist, make one\n",
    "        os.mkdir(query_term)\n",
    "        \n",
    "    headers = {\"Ocp-Apim-Subscription-Key\" : API_KEY}\n",
    "    params = {\"q\": query_term,\n",
    "              \"count\": 150, \n",
    "              \"offset\": offset * 150}\n",
    "\n",
    "    # Search Bing for images\n",
    "    search = requests.get(URL, headers=headers, params=params)\n",
    "    results = search.json()\n",
    "    \n",
    "    print('TOTAL ESTIMATED MATCHES: ' + str(results['totalEstimatedMatches']))\n",
    "\n",
    "    # Save all of the resulting images from each page\n",
    "    num = offset * 150\n",
    "    for value in results['value']:\n",
    "\n",
    "        print(str(num) + ' ' + value['contentUrl'], end='\\r')\n",
    "        \n",
    "        try:\n",
    "            image = requests.get(value[\"contentUrl\"], timeout=30, headers={'User-Agent': USER_AGENT})\n",
    "            \n",
    "        except(requests.ConnectionError):\n",
    "            print(str(num) + ' BAD CONNECTION', end='\\r')\n",
    "            continue\n",
    "            \n",
    "        except(requests.ReadTimeout):\n",
    "            print(str(num) + ' TIMEOUT', end='\\r')\n",
    "            continue\n",
    "        \n",
    "        # Check the status of the request - If the image does not exist we will skip it\n",
    "        try:\n",
    "            image.raise_for_status()\n",
    "            \n",
    "            file = open(path + query_term + '_' + str(offset) + '_' + str(num) + '.png', 'wb')\n",
    "            file.write(image.content)\n",
    "            file.close()\n",
    "            \n",
    "        except(requests.HTTPError):\n",
    "            print(str(num) + ' NOT FOUND', end='\\r')\n",
    "            \n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_format(folder):\n",
    "    '''\n",
    "    read in all images in given folder, format them, and put them into a master array\n",
    "    return x_data array, y_data array\n",
    "    '''\n",
    "    \n",
    "    x_data = np.array([])\n",
    "    Y_data = np.array([])\n",
    "    \n",
    "    # Iterate through each file in the specified folder\n",
    "    for file in os.listdir(folder):\n",
    "        \n",
    "        print(file, end='\\r')\n",
    "        \n",
    "        # Read in the image\n",
    "        try:\n",
    "            img = np.array(Image.open(folder + '/' + file))\n",
    "        except(IOError):\n",
    "            print('Image not found')\n",
    "            continue\n",
    "        \n",
    "        # If the image is greyscale, discard it\n",
    "        if len(img.shape) == 2:\n",
    "            continue\n",
    "        \n",
    "        # If the image is 4 channel (RGBA), convert to 3 channel (RGB)\n",
    "        if (len(img.shape) > 2) & (img.shape[2] == 4):\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "        \n",
    "        # Identify which sides need to be padded and by how much, to make the image square\n",
    "        short = np.argmin(img.shape[:2])\n",
    "        diff_1 = int(np.ceil(abs(img.shape[1] - img.shape[0])/2))\n",
    "        diff_2 = int(np.floor(abs(img.shape[1] - img.shape[0])/2))\n",
    "        \n",
    "        # Set the desired padding on the short side, and apply\n",
    "        width = [[0, 0], [0, 0], [0, 0]]\n",
    "        width[short] = [diff_1, diff_2]\n",
    "        img = np.pad(img, pad_width=width, mode='constant')\n",
    "        \n",
    "        # Resize square image to 100x100\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        \n",
    "        # Reshape array to be appended to x_data array\n",
    "        img = img.reshape(1, 100, 100, 3)\n",
    "        \n",
    "        # Put the formatted arrays into a master array of training data\n",
    "        if np.array_equal(x_data, np.array([])):\n",
    "            # This is the first one, start the array\n",
    "            x_data = img\n",
    "            \n",
    "        else:\n",
    "            # Append to full array\n",
    "            x_data = np.concatenate((x_data, img), axis=0)\n",
    "        \n",
    "        # The class label will be same as the name of the folder\n",
    "        Y_data = np.append(Y_data, folder)\n",
    "    \n",
    "    return x_data, Y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the images from search queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL ESTIMATED MATCHES: 471\n",
      "149 http://3.bp.blogspot.com/_ShlDb5rkkW4/TL8Njcn5R1I/AAAAAAAAAD8/Tf12BWJL_6w/s1600/upset_tabby_cat_05.JPGat+breed_042.jpgs-17.jpg925.jpgploads/chorus_image/image/56204307/GettyImages_507201978.0.jpgrthair-small-to-medium-sized-cats-cat-like-mammal-domestic-short-haired-cat-pixie-bob-toyger-1049556.jpg\r"
     ]
    }
   ],
   "source": [
    "img_save('cat', 0)\n",
    "img_save('cat', 1)\n",
    "img_save('cat', 2)\n",
    "img_save('cat', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL ESTIMATED MATCHES: 477\n",
      "TOTAL ESTIMATED MATCHES: 477D1xgR3Jvwo/hqdefault.jpg.jpg01/cho-gam-xuong-tapchichomeo.com_.jpgo-nu/33108-dog-flowers.JPGdu_after_Kukur_Puja.jpg120807x9Us_nGv0f-jKTG8_UinfF707bkJFz9bVwWS7M=\n",
      "TOTAL ESTIMATED MATCHES: 482/_UTzIAi3vBcY/TQ2b3Y9-WgI/AAAAAAAAA0E/bKDw6b_lY9Q/s1600/WebHund62010.jpgl.jpgdrodysplasia-skeletal-dwarfism.jpg0728120807jpgackgrounds-animal.jpgdadi.jpg\n",
      "TOTAL ESTIMATED MATCHES: 482g.uk/dogimages/1237659_adele_20200222082606_adele-g-hound-1-(2)_800.jpgjpggpgcover-image-732x412.jpgSwimming-Preserver-Summer-Swimwear_ce16de60-4141-4f25-bb67-f37921ece882_1200x1200.jpg?v=1582154787-Dog_relief_from_me%CA%BBae_I%CA%BBipona%2C_Puama%CA%BBu_Village%2C_Hiva_Oa%2C_Marquesas_Islands%2C_photograph_by_Moth_Clark%2C_2009_%28levels_adjusted%29.jpg\n",
      "481 https://visitcooma.com.au/wp-content/uploads/2020/02/Cooma-Visitors-Centre-Barrel-Racing-26-apr-cooma.jpgjpggel-for-and-medium-size-easy-to-cheap.jpgdog.jpg\r"
     ]
    }
   ],
   "source": [
    "img_save('dog', 0)\n",
    "img_save('dog', 1)\n",
    "img_save('dog', 2)\n",
    "img_save('dog', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL ESTIMATED MATCHES: 666\n",
      "TOTAL ESTIMATED MATCHES: 666661kKremyk/maxresdefault.jpg11/10/img_3668_crop.jpg181-brown_tree_snake_boiga_irregularis_-spl.jpgm1VO347jJGrJ3Na7Ed4.jpeg?imwidth=450-elapidae-emydidae-scaled-reptile-1386581.jpg\n",
      "TOTAL ESTIMATED MATCHES: 6661.1449254989!/fileImage/httpImage/image.png_gen/derivatives/16x9_1180/rattlesnake-with-fungal-infection.png1QiT4Uvmb-TOYSvIjNj5sFqJg0igJb7b-_Q=rix_helvetica%29_playing_dead_%2814178349634%29.jpg-head-photograph-snake-rattlesnake-up-still-sony-detail-manual-dof-body-alpha-snakes-short-medium-garter-m42-jupiter-serpent-slither-telephoto-a330-jupiter37a-37a-basking-organism-viper-grass-snake-garter-snake-colubridae-sidewinder-scaled-reptile-lacertidae-hognose-snake-kingsnake-terrestrial-animal-527141.jpg\n",
      "TOTAL ESTIMATED MATCHES: 666/wp-content/uploads/2015/02/Titanoboa-11-1024x760.jpglithering-surprise-australian-woman-finds-snake-on-her-christmas-tree/_jcr_content/par/featured-media/media-0.img.jpg/0/0/1482165352895.jpg?ve=1er_Paplanus.jpgviper-southern-pacific-crotalus-viridis-helleri-lethal-scaled-reptile-hognose-snake-kingsnake-662138.jpg.jpg\n",
      "599 https://creazilla-store.fra1.digitaloceanspaces.com/vectors/15489/snake-vector-medium.jpeg3f7359289ae856/f/r/fr-31687-womens-egyptian-cleopatra-goddess-adder-snake-asp-armband-700.jpg?strip=infoy_King_Kong_and_the_Snake.jpg9.jpganus.jpg\r"
     ]
    }
   ],
   "source": [
    "img_save('snake', 0)\n",
    "img_save('snake', 1)\n",
    "img_save('snake', 2)\n",
    "img_save('snake', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL ESTIMATED MATCHES: 969\n",
      "TOTAL ESTIMATED MATCHES: 969/-Uskp0bKYGok/TmxNx-8_yOI/AAAAAAAAA4U/bVBXY131rIc/s1600/penguin_3.jpgIMG_7756_352085.jpgjpg807a63557a-2060x1236.jpeg?w=1200&q=55&auto=format&usm=12&fit=max&s=349a333b7929f9c0c9343ae0f5720445Rakiura+penguins+beautiful+amazing+animal+pictures.jpg\n",
      "TOTAL ESTIMATED MATCHES: 969ca.com/blog/advocacy/wp-content/uploads/emperor-penguin.jpg0-p-k-no-nu/Emperor+Penguin1.jpgg2%2C2877%2C1922&q=45&auto=format&w=496&fit=clipgs=503cdb6b67cad5d3fabf3953d40fa74cIsland+penguins+Rakiura+penguins+beautiful+amazing+animal+pictures.jpg\n",
      "TOTAL ESTIMATED MATCHES: 969.org.nz/sites/all/files/4701112X2A7636%20-%20Copy%20ps%20ed%20crop%20bol.jpgx-LittlePenguin_PerthZoo_SMCSept05.jpg-3840x2400.jpgctica-polar-regions.jpgLBrd-01-09-2016-Daily-1-D002--2016-01-08-IMG-7-Little-Blue-Pengui-1-1-GED3JGFE-L740593295-IMG-7-Little-Blue-Pengui-1-1-GED3JGFE.jpg\n",
      "597 https://3.bp.blogspot.com/-d46zncdrY8s/TjPk81f3NDI/AAAAAAAAARs/068DnNB0giE/s1600/Yellow-eyed-Penguin.jpgpgjpgwing.pngcies-pingvin-located-in-the-south-Atlantic-and-elsewhere-Desktop-HD-Wallpaper-For-PC-Tablet-And-Mobile-1920x1200-1440x900.jpg5.jpg\r"
     ]
    }
   ],
   "source": [
    "img_save('penguin', 0)\n",
    "img_save('penguin', 1)\n",
    "img_save('penguin', 2)\n",
    "img_save('penguin', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL ESTIMATED MATCHES: 960\n",
      "TOTAL ESTIMATED MATCHES: 958.uk/content/dam/science/2017/11/03/shutterstock_736129444_trans_NvBQzQNjv4BqZgEkZX3M936N5BQK4Va8RUbgHFEZVI1Pljic_pW9c90.jpg?imwidth=4500fb0026652224.jpgdf78c3c4f806171.jpgon-154724035-59ce93949abed50011352530.jpg\n",
      "TOTAL ESTIMATED MATCHES: 959com/wp-content/gallery/swim-with-dolphins-article/Dolphind.jpg422282248365.adapt.1900.1.jpgl/-/media/2015/01/06/Phoenix/Phoenix/635561620095703087-4-14---Dolphin.jpgHusbandry-20-Edit.jpgy,P3D420,P26q,P3D85,P26i,P3D,P2Fdocuments,P2Ffeatures,P2Fimages,P2F25872_dolphins.jpg.pagespeed.ic.6WsmFtgz98.jpg\n",
      "TOTAL ESTIMATED MATCHES: 959st.com/resizer/fecjxmtSXJZURawZqfhTOkLSR8I=/1484x0/arc-anglerfish-washpost-prod-washpost.s3.amazonaws.com/public/CTAPM5XSVFBVVPNMHE4R526SJI.jpgapt.1900.1.jpgphin.jpg\n",
      "599 https://i.ytimg.com/vi/H4nr7LXjV40/hqdefault.jpg5/11/Common-Dolphin-and-Calf.jpg4e26bf5587c81934953e19f6e5884722.jpg.GIFbottlenose_dolphin.jpg30e.jpgis%29-B.pngns-and-porpoises-stenella-common-bottlenose-dolphin-short-beaked-common-dolphin-rough-toothed-dolphin-striped-dolphin-930129.jpg\r"
     ]
    }
   ],
   "source": [
    "img_save('dolphin', 0)\n",
    "img_save('dolphin', 1)\n",
    "img_save('dolphin', 2)\n",
    "img_save('dolphin', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format the images and save to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_3_467.png\r"
     ]
    }
   ],
   "source": [
    "x_cat, Y_cat = img_format('cat')\n",
    "x_dog, Y_dog = img_format('dog')\n",
    "x_snake, Y_snake = img_format('snake')\n",
    "x_penguin, Y_penguin = img_format('penguin')\n",
    "x_dolphin, Y_dolphin = img_format('dolphin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_cat, x_dog, x_snake, x_penguin, x_dolphin))\n",
    "Y_train = np.concatenate((Y_cat, Y_dog, Y_snake, Y_penguin, Y_dolphin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[Y_train == 'cat'] = 0\n",
    "Y_train[Y_train == 'dog'] = 1\n",
    "Y_train[Y_train == 'snake'] = 2\n",
    "Y_train[Y_train == 'penguin'] = 3\n",
    "Y_train[Y_train == 'dolphin'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.add(Dense(16, input_shape=x_train[0].shape, activation='relu'))\n",
    "nn_model.add(Dense(16,  activation='relu'))\n",
    "nn_model.add(Flatten())\n",
    "nn_model.add(Dense(len(np.unique(Y_train)),  activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100, 100, 16)      64        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100, 100, 16)      272       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 160000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 800005    \n",
      "=================================================================\n",
      "Total params: 800,341\n",
      "Trainable params: 800,341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2008 samples\n",
      "Epoch 1/10\n",
      "2008/2008 [==============================] - 9s 5ms/sample - loss: 161.1009 - accuracy: 0.4841\n",
      "Epoch 2/10\n",
      "2008/2008 [==============================] - 8s 4ms/sample - loss: 24.2865 - accuracy: 0.6121\n",
      "Epoch 3/10\n",
      "2008/2008 [==============================] - 8s 4ms/sample - loss: 6.3226 - accuracy: 0.6997\n",
      "Epoch 4/10\n",
      "2008/2008 [==============================] - 8s 4ms/sample - loss: 2.3835 - accuracy: 0.7704\n",
      "Epoch 5/10\n",
      "2008/2008 [==============================] - 8s 4ms/sample - loss: 1.0731 - accuracy: 0.8292\n",
      "Epoch 6/10\n",
      "2008/2008 [==============================] - 8s 4ms/sample - loss: 0.5216 - accuracy: 0.8586\n",
      "Epoch 7/10\n",
      "2008/2008 [==============================] - 8s 4ms/sample - loss: 0.4718 - accuracy: 0.8760\n",
      "Epoch 8/10\n",
      "2008/2008 [==============================] - 8s 4ms/sample - loss: 0.4597 - accuracy: 0.9124\n",
      "Epoch 9/10\n",
      "2008/2008 [==============================] - 8s 4ms/sample - loss: 0.6502 - accuracy: 0.8969\n",
      "Epoch 10/10\n",
      "2008/2008 [==============================] - 8s 4ms/sample - loss: 0.3388 - accuracy: 0.9128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x197d467ff48>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nn_model.fit(x=x_train, y=Y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model/Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.save('nn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = load_model('nn_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_predict(img, nn_model):\n",
    "    '''\n",
    "    reads in a single image, proccesses it, and generates predictions from the neural network\n",
    "    assumes incoming image is square\n",
    "    returns prediction array\n",
    "    '''\n",
    "    \n",
    "    # Resize to 100x100\n",
    "    img = cv2.resize(img, (100, 100))\n",
    "    \n",
    "    # Reshape to NN friendly shape\n",
    "    img = img.reshape(1, 100, 100, 3)\n",
    "    \n",
    "    # Generate prediction array from given NN model\n",
    "    pred = nn_model.predict(img.astype(float))\n",
    "    \n",
    "    return pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred(nn_model, img, name):\n",
    "\n",
    "    nn_pred = img_predict(img, nn_model)\n",
    "    labels = ['cat', 'dog', 'snake', 'penguin', 'dolphin']\n",
    "\n",
    "    # Plot Image\n",
    "    fig = plt.figure()\n",
    "\n",
    "    plt.subplot2grid((3, 2), (0 ,0), rowspan=3)\n",
    "    plt.imshow(img)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    # Plot CNN Prediction\n",
    "    plt.subplot2grid((3,2), (1, 1))\n",
    "    plt.bar(list(range(len(nn_pred))), nn_pred, color='firebrick')\n",
    "    plt.xticks(np.arange(len(nn_pred)), labels)\n",
    "    plt.ylim([0, 1])\n",
    "    plt.title('Neural Network')\n",
    "    plt.yticks([0, .5, 1])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.set_size_inches(w=12,h=6)\n",
    "    \n",
    "    plt.savefig(name)\n",
    "    \n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_img = np.array(Image.open('test_images/strip_11.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(0, full_img.shape[0], 36):\n",
    "\n",
    "    img = full_img[n:612 + n]\n",
    "\n",
    "    plot_pred(nn_model, img, 'plots/plot_{}.png'.format(str(n).zfill(4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
