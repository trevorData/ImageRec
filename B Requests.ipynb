{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('Documents/Projects/ImageRec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_save(query_term, offset):\n",
    "    '''\n",
    "    saves and processes images for specified query, creates folder in directory if there isnt one\n",
    "    '''\n",
    "    \n",
    "    API_KEY = os.getenv('bing_search_api_key')\n",
    "    URL = \"https://api.cognitive.microsoft.com/bing/v7.0/images/search\"\n",
    "    USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko)' + \\\n",
    "                 'Chrome/80.0.3987.87 Safari/537.36'\n",
    "    \n",
    "    # set path with query term as file name\n",
    "    path = os.getcwd().replace('\\\\', '/') + '/' + str(query_term) + '/'\n",
    "    \n",
    "    if not os.path.exists(query_term):\n",
    "        # if the directory does not exist, make one\n",
    "        os.mkdir(query_term)\n",
    "        \n",
    "    headers = {\"Ocp-Apim-Subscription-Key\" : API_KEY}\n",
    "    params = {\"q\": query_term,\n",
    "              \"count\": 150, \n",
    "              \"offset\": offset * 150}\n",
    "\n",
    "    # Search Bing for images\n",
    "    search = requests.get(URL, headers=headers, params=params)\n",
    "    results = search.json()\n",
    "    \n",
    "    print('TOTAL ESTIMATED MATCHES: ' + str(results['totalEstimatedMatches']))\n",
    "\n",
    "    # Save all of the resulting images from each page\n",
    "    num = offset * 150\n",
    "    for value in results['value']:\n",
    "\n",
    "        print(str(num) + ' ' + value['contentUrl'], end='\\r')\n",
    "        \n",
    "        try:\n",
    "            image = requests.get(value[\"contentUrl\"], timeout=30, headers={'User-Agent': USER_AGENT})\n",
    "            \n",
    "        except(requests.ConnectionError):\n",
    "            print(str(num) + ' BAD CONNECTION', end='\\r')\n",
    "            continue\n",
    "            \n",
    "        except(requests.ReadTimeout):\n",
    "            print(str(num) + ' TIMEOUT', end='\\r')\n",
    "            continue\n",
    "        \n",
    "        # Check the status of the request - If the image does not exist we will skip it\n",
    "        try:\n",
    "            image.raise_for_status()\n",
    "            \n",
    "            file = open(path + query_term + '_' + str(offset) + '_' + str(num) + '.png', 'wb')\n",
    "            file.write(image.content)\n",
    "            file.close()\n",
    "            \n",
    "        except(requests.HTTPError):\n",
    "            print(str(num) + ' NOT FOUND', end='\\r')\n",
    "            \n",
    "        num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_format(folder):\n",
    "    '''\n",
    "    read in all images in given folder, format them, and put them into a master array\n",
    "    return x_data array, y_data array\n",
    "    '''\n",
    "    \n",
    "    x_data = np.array([])\n",
    "    Y_data = np.array([])\n",
    "    \n",
    "    # Iterate through each file in the specified folder\n",
    "    for file in os.listdir(folder):\n",
    "        \n",
    "        print(file, end='\\r')\n",
    "        \n",
    "        # Read in the image\n",
    "        img = np.array(Image.open(folder + '/' + file))\n",
    "        \n",
    "        # If the image is greyscale, discard it\n",
    "        if len(img.shape) == 2:\n",
    "            continue\n",
    "        \n",
    "        # If the image is 4 channel (RGBA), convert to 3 channel (RGB)\n",
    "        if (len(img.shape) > 2) & (img.shape[2] == 4):\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
    "        \n",
    "        # Identify which sides need to be padded and by how much, to make the image square\n",
    "        short = np.argmin(img.shape[:2])\n",
    "        diff_1 = int(np.ceil(abs(img.shape[1] - img.shape[0])/2))\n",
    "        diff_2 = int(np.floor(abs(img.shape[1] - img.shape[0])/2))\n",
    "        \n",
    "        # Set the desired padding on the short side, and apply\n",
    "        width = [[0, 0], [0, 0], [0, 0]]\n",
    "        width[short] = [diff_1, diff_2]\n",
    "        img = np.pad(img, pad_width=width)\n",
    "        \n",
    "        # Resize square image to 100x100\n",
    "        img = cv2.resize(img, (100, 100))\n",
    "        \n",
    "        # Reshape array to be appended to x_data array\n",
    "        img = img.reshape(1, 100, 100, 3)\n",
    "        \n",
    "        # Put the formatted arrays into a master array of training data\n",
    "        if np.array_equal(x_data, np.array([])):\n",
    "            # This is the first one, start the array\n",
    "            x_data = img\n",
    "            \n",
    "        else:\n",
    "            # Append to full array\n",
    "            x_data = np.concatenate((x_data, img), axis=0)\n",
    "        \n",
    "        # The class label will be same as the name of the folder\n",
    "        Y_data = np.append(Y_data, folder)\n",
    "    \n",
    "    return x_data, Y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_process(img, nn_model):\n",
    "    '''\n",
    "    reads in a single image, proccesses it, and generates predictions from the neural network\n",
    "    assumes incoming image is square\n",
    "    returns prediction array\n",
    "    '''\n",
    "    \n",
    "    # Resize to 100x100\n",
    "    img = cv2.resize(img, (100, 100))\n",
    "    \n",
    "    # Reshape to NN friendly shape\n",
    "    img = img.reshape(1, 100, 100, 3, 1)\n",
    "    \n",
    "    # Generate prediction array from given NN model\n",
    "    pred = nn_model.predict(img.astype(float))\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.0406069e-15, 4.3367917e-14, 3.5749658e-16, 1.4462540e-07,\n",
       "        9.9999988e-01]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_process(img, nn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the images from search queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the images and save to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat_3_469.png\r"
     ]
    }
   ],
   "source": [
    "x_cat, Y_cat = img_format('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog_3_488.png\r"
     ]
    }
   ],
   "source": [
    "x_dog, Y_dog = img_format('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "snake_3_583.png\r"
     ]
    }
   ],
   "source": [
    "x_snake, Y_snake = img_format('snake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penguin_3_599.png\r"
     ]
    }
   ],
   "source": [
    "x_penguin, Y_penguin = img_format('penguin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dolphin_3_599.png\r"
     ]
    }
   ],
   "source": [
    "x_dolphin, Y_dolphin = img_format('dolphin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((x_cat, x_dog, x_snake, x_penguin, x_dolphin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train), 100, 100, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.concatenate((Y_cat, Y_dog, Y_snake, Y_penguin, Y_dolphin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train[Y_train == 'cat'] = 0\n",
    "Y_train[Y_train == 'dog'] = 1\n",
    "Y_train[Y_train == 'snake'] = 2\n",
    "Y_train[Y_train == 'penguin'] = 3\n",
    "Y_train[Y_train == 'dolphin'] = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = Y_train.astype(np.int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model.add(Dense(16, input_shape=x_train[0].shape, activation='relu'))\n",
    "nn_model.add(Dense(16,  activation='relu'))\n",
    "nn_model.add(Flatten())\n",
    "nn_model.add(Dense(len(np.unique(Y_train)),  activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100, 100, 3, 16)   32        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100, 100, 3, 16)   272       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 480000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 2400005   \n",
      "=================================================================\n",
      "Total params: 2,400,309\n",
      "Trainable params: 2,400,309\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2451 samples\n",
      "Epoch 1/10\n",
      "2451/2451 [==============================] - 22s 9ms/sample - loss: 800.5372 - accuracy: 0.4109\n",
      "Epoch 2/10\n",
      "2451/2451 [==============================] - 21s 8ms/sample - loss: 79.8018 - accuracy: 0.5557\n",
      "Epoch 3/10\n",
      "2451/2451 [==============================] - 21s 9ms/sample - loss: 32.6090 - accuracy: 0.5916\n",
      "Epoch 4/10\n",
      "2451/2451 [==============================] - 22s 9ms/sample - loss: 7.6242 - accuracy: 0.6691\n",
      "Epoch 5/10\n",
      "2451/2451 [==============================] - 22s 9ms/sample - loss: 1.0181 - accuracy: 0.7609\n",
      "Epoch 6/10\n",
      "2451/2451 [==============================] - 23s 9ms/sample - loss: 0.6052 - accuracy: 0.7968\n",
      "Epoch 7/10\n",
      "2451/2451 [==============================] - 23s 9ms/sample - loss: 0.5990 - accuracy: 0.8001\n",
      "Epoch 8/10\n",
      "2451/2451 [==============================] - 25s 10ms/sample - loss: 0.5799 - accuracy: 0.8099\n",
      "Epoch 9/10\n",
      "2451/2451 [==============================] - 22s 9ms/sample - loss: 0.5776 - accuracy: 0.8070\n",
      "Epoch 10/10\n",
      "2451/2451 [==============================] - 21s 9ms/sample - loss: 0.5510 - accuracy: 0.8193\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20dbb923630>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nn_model.fit(x=x_train,y=Y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.01032878e-04, 8.24486429e-04, 1.17715805e-04, 3.37377749e-02,\n",
       "        9.65218961e-01]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.predict(x_train[2001].reshape(1, 100, 100, 3, 1).astype(float))#.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
